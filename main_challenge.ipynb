{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bf11d07-9856-42da-8125-3099f10e0669",
   "metadata": {},
   "source": [
    "## Environment Setting\n",
    "Google drive mount (for Colab users) and package importing.\n",
    "You can optionally work on a transformer part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280812e1-0a56-4cf8-b6a7-7620874d9624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Colab users\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'/content/drive/{path to project directory}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b82d731-fc8f-4681-8e8b-614b58e21bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import json\n",
    "\n",
    "from data_utils import MLDataset, collate_fn\n",
    "from modeling import Seq2SeqModel # You can import your custom model classes from modeling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78120bd-5408-45b6-9ea1-ec1f080349ca",
   "metadata": {},
   "source": [
    "## (Optional) Sample Visualization\n",
    "You can see actual sample images and correct answers. Additional matplotlib package is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55336728-8e6c-4a3c-bf3d-b06e676b70ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for reference: see actual samples\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "id_to_char = {}\n",
    "alphabets = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "for i, c in enumerate(alphabets):\n",
    "    id_to_char[i+1] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f4666f-5a79-47aa-94f7-00c85f938460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for reference: see actual samples\n",
    "idx = 1234\n",
    "sample = np.load(f'./data_final/imgs/train/{idx}.npy')\n",
    "with open('./data_final/labels/train.json', 'r') as f:\n",
    "    sample_target = json.load(f)[str(idx)]\n",
    "    \n",
    "tgt_char = \"\"\n",
    "for i in sample_target:\n",
    "    tgt_char += id_to_char[i]\n",
    "\n",
    "\n",
    "print(f\"Answer: {tgt_char} ({sample_target})\")\n",
    "print(\"Input image sequence:\")\n",
    "\n",
    "plt.figure(figsize=(5, len(sample)))\n",
    "for i, img in enumerate(sample):    \n",
    "    plt.subplot(1, len(sample), i+1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400da0bd-7c64-4d23-a24b-b0d097d995ae",
   "metadata": {},
   "source": [
    "## Device and seed setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4579ad2-6031-450c-a30c-cbf5b69fbfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()\n",
    "\n",
    "# Use 0th GPU for training\n",
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# fix random seed to increase reproducibility\n",
    "# NOTE: Do not modify here!\n",
    "NUM_CLASSES = 26 + 2 # 26 alphabets + 1 padding index + 1 <s> token (start token)\n",
    "\n",
    "random_seed = 7\n",
    "torch.manual_seed(random_seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# %env CUBLAS_WORKSPACE_CONFIG=:16:8\n",
    "\n",
    "def seed_worker(worker_seed):\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc6523c-962c-42fb-bbaa-38d8236797eb",
   "metadata": {},
   "source": [
    "## Model loading and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffaa119-e2d5-4f4e-a663-5578c4f49359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: modify path and batch size for your setting\n",
    "# NOTE: you can apply custom preprocessing to the training data\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_ds = MLDataset('data_final/imgs/train', 'data_final/labels/train.json')\n",
    "valid_ds = MLDataset('data_final/imgs/valid_normal', 'data_final/labels/valid_normal.json')\n",
    "challenge_ds = MLDataset('data_final/imgs/valid_challenge', 'data_final/labels/valid_challenge.json')\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False)\n",
    "challenge_dl = DataLoader(challenge_ds, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77af1ae4-496f-4cbd-a2dc-9c429d052d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add or modify your Seq2SeqModel's hyperparameter (keys and values)\n",
    "kwargs = {\n",
    "    'hidden_dim': 32,\n",
    "    'n_rnn_layers': 2,\n",
    "    'rnn_dropout': 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595dcc8b-006e-4730-94f6-933c2c743996",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqModel(num_classes=NUM_CLASSES, **kwargs).to(device)\n",
    "print(model)\n",
    "##############################################################################\n",
    "#                          IMPLEMENT YOUR CODE                               #\n",
    "##############################################################################\n",
    "model_optim =\n",
    "loss_fn = \n",
    "# NOTE: you can define additional components like lr_scheduler, ...\n",
    "##############################################################################\n",
    "#                          END OF YOUR CODE                                  #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc52297-5653-4a17-8ec1-b529bb0e9c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: you can freely modify or add training hyperparameters\n",
    "print_interval = 1000\n",
    "max_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd18ddf1-a8d0-4ef6-a05f-ac4a38678b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_optim, loss_fn, max_epoch, train_dl, valid_dl, load_path=None, save_path='./model.pt'):\n",
    "    ##############################################################################\n",
    "    #                          IMPLEMENT YOUR CODE                               #\n",
    "    ##############################################################################\n",
    "    # Implement your train function\n",
    "    \n",
    "    ##############################################################################\n",
    "    #                          END OF YOUR CODE                                  #\n",
    "    ##############################################################################\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb670ac-6d52-458d-b9e8-ded745258c7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_path = None\n",
    "train(model, model_optim, loss_fn, max_epoch, train_dl, valid_dl, load_path=load_path, save_path='./model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e83246b-de55-4668-bb78-c1fbb6c7f60d",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f3646f-f3a3-4d7f-b71c-9665f11450d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_generate = {\n",
    "    # you can add arguments for your model's generate function\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce38064-e195-46c5-851c-43b116be5333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify this cell!\n",
    "\n",
    "def eval(dataloader, model_path):\n",
    "    state = torch.load(model_path)\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    model.eval()\n",
    "\n",
    "    id_to_char = {}\n",
    "    id_to_char[0] = \"<pad>\"\n",
    "    id_to_char[27] = \"<s>\"\n",
    "    alphabets = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    for i, c in enumerate(alphabets):\n",
    "        id_to_char[i+1] = c\n",
    "\n",
    "    results = []\n",
    "    labels = []    \n",
    "    for batch_idx, (data, target, lengths) in enumerate(tqdm(dataloader)):       \n",
    "        data = data.to(device) # (B, T, H, W, C)\n",
    "        target = target.to(device) # (B, T)\n",
    "        \n",
    "        # start tokens should be located at the first position of the decoder input\n",
    "        start_tokens = (torch.ones([target.size(0), 1]) * 27).to(torch.long).to(device)\n",
    "        with torch.no_grad():\n",
    "            generated_tok = model.generate(data, lengths, start_tokens, **kwargs_generate) # (B, T)\n",
    "            \n",
    "        for i in range(generated_tok.size(0)):\n",
    "            decoded = \"\"\n",
    "            for j in generated_tok[i][:lengths[i].int()].tolist():\n",
    "                decoded += id_to_char[j]\n",
    "            results.append(decoded)\n",
    "    \n",
    "            decoded = \"\"\n",
    "            for j in target[i][:lengths[i].int()].tolist():\n",
    "                decoded += id_to_char[j]\n",
    "            labels.append(decoded)\n",
    "        \n",
    "    corrects = []\n",
    "    for i in range(len(results)):\n",
    "        if results[i] == labels[i]:\n",
    "            corrects.append(1)\n",
    "        else:\n",
    "            corrects.append(0)\n",
    "    print(\"Accuracy: %.5f\" % (sum(corrects) / len(corrects)))\n",
    "\n",
    "    return results, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce11344-4b75-41a7-9701-9d372f840f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and evaluate your model\n",
    "load_path = './model.pt'\n",
    "print(\"Evaluation with validation set\")\n",
    "results, labels = eval(valid_dl, load_path)\n",
    "\n",
    "print(\"Evaluation with chllenge set\")\n",
    "results, labels = eval(challenge_dl, load_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2024",
   "language": "python",
   "name": "ml2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
