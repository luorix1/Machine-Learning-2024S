{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bf11d07-9856-42da-8125-3099f10e0669",
   "metadata": {},
   "source": [
    "## Environment Setting\n",
    "\n",
    "Google drive mount (for Colab users) and package importing.\n",
    "You can optionally work on a transformer part.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280812e1-0a56-4cf8-b6a7-7620874d9624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Colab users\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\", force_remount=True)\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"/content/drive/{path to project directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b82d731-fc8f-4681-8e8b-614b58e21bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import json\n",
    "\n",
    "from data_utils import MLDataset, collate_fn\n",
    "from modeling_challenge import Seq2SeqModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78120bd-5408-45b6-9ea1-ec1f080349ca",
   "metadata": {},
   "source": [
    "## (Optional) Sample Visualization\n",
    "\n",
    "You can see actual sample images and correct answers. Additional matplotlib package is needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55336728-8e6c-4a3c-bf3d-b06e676b70ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for reference: see actual samples\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "id_to_char = {}\n",
    "alphabets = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "for i, c in enumerate(alphabets):\n",
    "    id_to_char[i + 1] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f4666f-5a79-47aa-94f7-00c85f938460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for reference: see actual samples\n",
    "idx = 1234\n",
    "sample = np.load(f\"./data_final/imgs/train/{idx}.npy\")\n",
    "with open(\"./data_final/labels/train.json\", \"r\") as f:\n",
    "    sample_target = json.load(f)[str(idx)]\n",
    "\n",
    "tgt_char = \"\"\n",
    "for i in sample_target:\n",
    "    tgt_char += id_to_char[i]\n",
    "\n",
    "\n",
    "print(f\"Answer: {tgt_char} ({sample_target})\")\n",
    "print(\"Input image sequence:\")\n",
    "\n",
    "plt.figure(figsize=(5, len(sample)))\n",
    "for i, img in enumerate(sample):\n",
    "    plt.subplot(1, len(sample), i + 1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400da0bd-7c64-4d23-a24b-b0d097d995ae",
   "metadata": {},
   "source": [
    "## Device and seed setting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4579ad2-6031-450c-a30c-cbf5b69fbfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()\n",
    "\n",
    "# Use 0th GPU for training\n",
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# fix random seed to increase reproducibility\n",
    "# NOTE: Do not modify here!\n",
    "NUM_CLASSES = 26 + 2  # 26 alphabets + 1 padding index + 1 <s> token (start token)\n",
    "\n",
    "random_seed = 7\n",
    "torch.manual_seed(random_seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# %env CUBLAS_WORKSPACE_CONFIG=:16:8\n",
    "\n",
    "\n",
    "def seed_worker(worker_seed):\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc6523c-962c-42fb-bbaa-38d8236797eb",
   "metadata": {},
   "source": [
    "## Model loading and training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffaa119-e2d5-4f4e-a663-5578c4f49359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: modify path and batch size for your setting\n",
    "# NOTE: you can apply custom preprocessing to the training data\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_ds = MLDataset(\"data_final/imgs/train\", \"data_final/labels/train.json\")\n",
    "valid_ds = MLDataset(\n",
    "    \"data_final/imgs/valid_normal\", \"data_final/labels/valid_normal.json\"\n",
    ")\n",
    "challenge_ds = MLDataset(\n",
    "    \"data_final/imgs/valid_challenge\", \"data_final/labels/valid_challenge.json\"\n",
    ")\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True\n",
    ")\n",
    "valid_dl = DataLoader(\n",
    "    valid_ds, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False\n",
    ")\n",
    "challenge_dl = DataLoader(\n",
    "    challenge_ds, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77af1ae4-496f-4cbd-a2dc-9c429d052d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add or modify your Seq2SeqModel's hyperparameter (keys and values)\n",
    "kwargs = {\n",
    "    'hidden_dim': 256,       # Hidden dimension size for RNN\n",
    "    'nhead': 4,              # Number of attention heads in the Transformer\n",
    "    'dec_layers': 4,         # Number of layers in the Transformer decoder\n",
    "    'dim_feedforward': 1024, # Dimension of feedforward layers in the Transformer\n",
    "    'dropout': 0.2,          # Dropout rate for the Transformer\n",
    "    'enc_layers': 3,         # Number of RNN layers in the encoder\n",
    "    'rnn_dropout': 0.3,      # Dropout rate for the RNN in the encoder\n",
    "    'max_length': 11,        # Maximum length of the sequences\n",
    "    'cnn_settings': {        # Settings for the CustomCNN\n",
    "        'block1_dim': 32,\n",
    "        'block2_dim': 64,\n",
    "        'block3_dim': 128,\n",
    "        'fc_dim': 256,\n",
    "        'model_type': 'VGG'  # Type of CNN ('VGG' or 'ResNet')\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595dcc8b-006e-4730-94f6-933c2c743996",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqModel(num_classes=NUM_CLASSES, **kwargs).to(device)\n",
    "print(model)\n",
    "##############################################################################\n",
    "#                          IMPLEMENT YOUR CODE                               #\n",
    "##############################################################################\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# model_optim = torch.optim.Adam(model.parameters(), lr=0.001) # For training from scratch\n",
    "model_optim = torch.optim.Adam(model.parameters(), lr=0.0001) # For fine-tuning\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(model_optim, step_size=10, gamma=0.5)\n",
    "##############################################################################\n",
    "#                          END OF YOUR CODE                                  #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eca9395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of parameters for the model\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc52297-5653-4a17-8ec1-b529bb0e9c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: you can freely modify or add training hyperparameters\n",
    "print_interval = 1000\n",
    "max_epoch = 20\n",
    "patience = 2\n",
    "vis = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d903e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function\n",
    "def train(\n",
    "        model,\n",
    "        model_optim,\n",
    "        loss_fn,\n",
    "        max_epoch,\n",
    "        train_dl,\n",
    "        valid_dl,\n",
    "        load_path=None,\n",
    "        save_path='./model.pt',\n",
    "        patience=5,\n",
    "        initial_teacher_forcing_ratio=1.0,\n",
    "        teacher_forcing_decay=0.95,\n",
    "        scheduler=None,\n",
    "        device='cuda'\n",
    "    ):\n",
    "    # Load the model state if a checkpoint is provided\n",
    "    loaded_epoch = 0\n",
    "    loaded_best_valid_loss = -1\n",
    "    if load_path is not None:\n",
    "        state = torch.load(load_path)\n",
    "        model.load_state_dict(state[\"model\"])\n",
    "        model_optim.load_state_dict(state[\"optimizer\"])\n",
    "        loaded_epoch = state[\"epoch\"]\n",
    "        loaded_best_valid_loss = state[\"best_valid_loss\"]\n",
    "        \n",
    "    best_valid_loss = 1e+10 if loaded_best_valid_loss == -1 else loaded_best_valid_loss\n",
    "    no_improvement_epochs = 0\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    accuracies = []\n",
    "\n",
    "    teacher_forcing_ratio = initial_teacher_forcing_ratio\n",
    "\n",
    "    for epoch in np.array(list(range(max_epoch - loaded_epoch))) + loaded_epoch:\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for _, (data, target, lengths) in enumerate(tqdm(train_dl)):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            start_tokens = (torch.ones([target.size(0), 1]) * 27).to(torch.long).to(device)\n",
    "\n",
    "            # Teacher forcing\n",
    "            decoder_input = torch.cat([start_tokens, target[:, :-1]], dim=1)\n",
    "            \n",
    "            model_optim.zero_grad()\n",
    "                        \n",
    "            output = model(data, lengths, decoder_input, teacher_forcing_ratio)\n",
    "\n",
    "            # Ensure the shapes are correctly matched\n",
    "            output = output.contiguous().view(-1, NUM_CLASSES)  # (batch_size * seq_len, num_classes)\n",
    "            target = target.contiguous().view(-1)  # (batch_size * seq_len)\n",
    "            \n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            model_optim.step()\n",
    "            train_loss += loss.detach().cpu().item()\n",
    "\n",
    "        train_loss_avg = train_loss / len(train_dl)\n",
    "        train_losses.append(train_loss_avg)\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        valid_loss = 0\n",
    "        correct_sequences = 0\n",
    "        total_sequences = 0\n",
    "\n",
    "        model.eval()\n",
    "        for _, (data, target, lengths) in enumerate(tqdm(valid_dl)):            \n",
    "            with torch.no_grad():\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                start_tokens = (torch.ones([target.size(0), 1]) * 27).to(torch.long).to(device)\n",
    "                \n",
    "                decoder_input = torch.cat([start_tokens, target[:, :-1]], dim=1)\n",
    "                output = model(data, lengths, decoder_input, teacher_forcing_ratio=0.0)  # No teacher forcing during validation\n",
    "                \n",
    "                # Ensure the shapes are correctly matched\n",
    "                output = output.contiguous().view(-1, output.size(-1))  # (batch_size * seq_len, num_classes)\n",
    "                target = target.contiguous().view(-1)  # (batch_size * seq_len)\n",
    "                \n",
    "                loss = loss_fn(output, target)\n",
    "                valid_loss += loss.cpu().item()\n",
    "\n",
    "                logits = output.view(data.size(0), -1, output.size(-1))\n",
    "                predicted_sequences = torch.argmax(logits, dim=-1)\n",
    "                for i in range(data.size(0)):\n",
    "                    pred_seq = predicted_sequences[i][:int(lengths[i])]\n",
    "                    target_seq = target.view(data.size(0), -1)[i][:int(lengths[i])]\n",
    "                    if torch.equal(pred_seq, target_seq):\n",
    "                        correct_sequences += 1\n",
    "                    total_sequences += 1\n",
    "        \n",
    "        valid_loss /= len(valid_dl)\n",
    "        accuracy = correct_sequences / total_sequences\n",
    "        accuracies.append(accuracy)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            print(\"New best valid loss, saving model\")\n",
    "            state = {\n",
    "                \"model\": model.state_dict(),\n",
    "                \"optimizer\": model_optim.state_dict(),\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"best_valid_loss\": valid_loss,\n",
    "            }\n",
    "            torch.save(state, save_path)\n",
    "            best_valid_loss = valid_loss\n",
    "            no_improvement_epochs = 0\n",
    "        else:\n",
    "            no_improvement_epochs += 1\n",
    "\n",
    "        print(f'epoch {epoch + 1}, train loss: {train_loss_avg:.4f}, valid loss: {valid_loss:.4f}, best valid loss: {best_valid_loss:.4f}, accuracy: {accuracy:.4f}')\n",
    "\n",
    "        teacher_forcing_ratio *= teacher_forcing_decay\n",
    "\n",
    "        if no_improvement_epochs >= patience:\n",
    "            print(f\"No improvement in validation loss for {patience} epochs. Stopping training.\")\n",
    "            break\n",
    "\n",
    "    return train_losses, valid_losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e6083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, valid_losses, accuracies = train(\n",
    "    model,\n",
    "    model_optim,\n",
    "    loss_fn,\n",
    "    max_epoch=20,\n",
    "    train_dl=train_dl,\n",
    "    valid_dl=valid_dl,\n",
    "    load_path=None,\n",
    "    save_path='./model.pt',\n",
    "    patience=2,\n",
    "    initial_teacher_forcing_ratio=1.0,\n",
    "    teacher_forcing_decay=0.95,\n",
    "    scheduler=scheduler,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a49328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation losses over epochs\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"train loss\")\n",
    "plt.plot(valid_losses, label=\"valid loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4312df66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation accuracy over epochs\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(accuracies, label='validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e83246b-de55-4668-bb78-c1fbb6c7f60d",
   "metadata": {},
   "source": [
    "## Model evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f3646f-f3a3-4d7f-b71c-9665f11450d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_generate = {\n",
    "    \"max_length\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce38064-e195-46c5-851c-43b116be5333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify this cell!\n",
    "\n",
    "\n",
    "def eval(dataloader, model_path):\n",
    "    state = torch.load(model_path)\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    model.eval()\n",
    "\n",
    "    id_to_char = {}\n",
    "    id_to_char[0] = \"<pad>\"\n",
    "    id_to_char[27] = \"<s>\"\n",
    "    alphabets = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    for i, c in enumerate(alphabets):\n",
    "        id_to_char[i + 1] = c\n",
    "\n",
    "    results = []\n",
    "    labels = []\n",
    "    for batch_idx, (data, target, lengths) in enumerate(tqdm(dataloader)):\n",
    "        data = data.to(device)  # (B, T, H, W, C)\n",
    "        target = target.to(device)  # (B, T)\n",
    "\n",
    "        # start tokens should be located at the first position of the decoder input\n",
    "        start_tokens = (torch.ones([target.size(0), 1]) * 27).to(torch.long).to(device)\n",
    "        with torch.no_grad():\n",
    "            generated_tok = model.generate(\n",
    "                data, lengths, start_tokens, **kwargs_generate\n",
    "            )  # (B, T)\n",
    "\n",
    "        for i in range(generated_tok.size(0)):\n",
    "            decoded = \"\"\n",
    "            for j in generated_tok[i][: lengths[i].int()].tolist():\n",
    "                decoded += id_to_char[j]\n",
    "            results.append(decoded)\n",
    "\n",
    "            decoded = \"\"\n",
    "            for j in target[i][: lengths[i].int()].tolist():\n",
    "                decoded += id_to_char[j]\n",
    "            labels.append(decoded)\n",
    "\n",
    "    corrects = []\n",
    "    for i in range(len(results)):\n",
    "        if results[i] == labels[i]:\n",
    "            corrects.append(1)\n",
    "        else:\n",
    "            corrects.append(0)\n",
    "    print(\"Accuracy: %.5f\" % (sum(corrects) / len(corrects)))\n",
    "\n",
    "    return results, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce11344-4b75-41a7-9701-9d372f840f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and evaluate your model\n",
    "load_path = \"./model.pt\"\n",
    "print(\"Evaluation with validation set\")\n",
    "results, labels = eval(valid_dl, load_path)\n",
    "\n",
    "print(\"Evaluation with challenge set\")\n",
    "results, labels = eval(challenge_dl, load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0734a98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
